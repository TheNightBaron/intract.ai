{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "604e3a57",
   "metadata": {},
   "source": [
    "## Goal(s)\n",
    "### Cluster subject lines and test out their CTR using online tools (if available)\n",
    "#### 1. Different ways of embedding sentences\n",
    "##### a. Average word2vec\n",
    "##### b. word2vec -> TFIDF (multiply word2vec and tfidf representations of words and take average)\n",
    "##### c. Pre-trained FastText\n",
    "##### d. Self-trained FastText\n",
    "\n",
    "##### Experiment with stop words, proper nouns etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "ab6aecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "import json\n",
    "import numpy as np\n",
    "import gensim.models\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "36b08195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__testing_word2vec-matrix-synopsis (-1 records): [THIS IS ONLY FOR TESTING] Word vecrors of the movie matrix....\n",
      "conceptnet-numberbatch-17-06-300 (1917247 records): ConceptNet Numberbatch consists of state-of-the-art semantic vectors (...\n",
      "fasttext-wiki-news-subwords-300 (999999 records): 1 million word vectors trained on Wikipedia 2017, UMBC webbase corpus ...\n",
      "glove-twitter-100 (1193514 records): Pre-trained vectors based on  2B tweets, 27B tokens, 1.2M vocab, uncas...\n",
      "glove-twitter-200 (1193514 records): Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncase...\n",
      "glove-twitter-25 (1193514 records): Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncase...\n",
      "glove-twitter-50 (1193514 records): Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncase...\n",
      "glove-wiki-gigaword-100 (400000 records): Pre-trained vectors based on Wikipedia 2014 + Gigaword 5.6B tokens, 40...\n",
      "glove-wiki-gigaword-200 (400000 records): Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 4...\n",
      "glove-wiki-gigaword-300 (400000 records): Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 4...\n",
      "glove-wiki-gigaword-50 (400000 records): Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 4...\n",
      "word2vec-google-news-300 (3000000 records): Pre-trained vectors trained on a part of the Google News dataset (abou...\n",
      "word2vec-ruscorpora-300 (184973 records): Word2vec Continuous Skipgram vectors trained on full Russian National ...\n"
     ]
    }
   ],
   "source": [
    "info = api.info()\n",
    "for model_name, model_data in sorted(info['models'].items()):\n",
    "    print(\n",
    "        '%s (%d records): %s' % (\n",
    "            model_name,\n",
    "            model_data.get('num_records', -1),\n",
    "            model_data['description'][:70] + '...',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "0a4a515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-newsgroups (18846 records)\n",
      "__testing_matrix-synopsis (-1 records)\n",
      "__testing_multipart-matrix-synopsis (-1 records)\n",
      "fake-news (12999 records)\n",
      "patent-2017 (353197 records)\n",
      "quora-duplicate-questions (404290 records)\n",
      "semeval-2016-2017-task3-subtaskA-unannotated (189941 records)\n",
      "semeval-2016-2017-task3-subtaskBC (-1 records)\n",
      "text8 (1701 records)\n",
      "wiki-english-20171001 (4924894 records)\n"
     ]
    }
   ],
   "source": [
    "for corpus_name, corpus_data in sorted(info['corpora'].items()):\n",
    "    print(\n",
    "#         '%s (%d records): %s' % (\n",
    "        '%s (%d records)' % (\n",
    "            corpus_name,\n",
    "            corpus_data.get('num_records', -1),\n",
    "#             corpus_data['description'][:70] + '...',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "369fa11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_records': 1701,\n",
       " 'record_format': 'list of str (tokens)',\n",
       " 'file_size': 33182058,\n",
       " 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/__init__.py',\n",
       " 'license': 'not found',\n",
       " 'description': 'First 100,000,000 bytes of plain text from Wikipedia. Used for testing purposes; see wiki-english-* for proper full Wikipedia datasets.',\n",
       " 'checksum': '68799af40b6bda07dfa47a32612e5364',\n",
       " 'file_name': 'text8.gz',\n",
       " 'read_more': ['http://mattmahoney.net/dc/textdata.html'],\n",
       " 'parts': 1}"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['corpora']['text8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "175dd1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = api.load('wiki-english-20171001')\n",
    "### Too big dataset; will download later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "5f442ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_update_dataset():\n",
    "    #Import data\n",
    "    emails = pd.read_excel(r\"C:\\Users\\Harsh Garg\\Desktop\\intract\\Email Subject Line Scrapper.xlsx\",'Saved Data')\n",
    "\n",
    "    #Delete irrelevant columns and add relevant columns\n",
    "    emails = emails[['Subject Line']]\n",
    "    \n",
    "    \n",
    "    return list(emails['Subject Line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b500e",
   "metadata": {},
   "source": [
    "#### Adding emails to text8 vocabulary because word2vec cannot handle OOV words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "097c1f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = create_update_dataset()\n",
    "for index, sentence in enumerate(new_sentences):\n",
    "    new_sentences[index] = sentence.split()\n",
    "\n",
    "sentences = api.load('text8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "550393ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    new_sentences = new_sentences + sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "3af237cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "def reemovNestings(l):\n",
    "    for i in l:\n",
    "        if type(i) == list:\n",
    "            reemovNestings(i)\n",
    "        else:\n",
    "            output.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd76fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reemovNestings(new_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "76234914",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output + ['fear']\n",
    "output = output + ['anticipation']\n",
    "output = output + ['joy']\n",
    "output = output + ['trust']\n",
    "output = output + ['pride']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "ef8db530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28135312, 166099895)"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Takes A LOT of time to train :(\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences=output,vector_size=100, window=2, min_count=1, workers=4)\n",
    "model.train(output, total_examples=len(output), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "68439b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_distance(point, centroid):\n",
    "    dist = 0\n",
    "    for index, value in enumerate(point):\n",
    "        dist += abs(value - centroid[index])\n",
    "    return dist\n",
    "\n",
    "def square_distance(point, centroid):\n",
    "    dist = 0\n",
    "    for index, value in enumerate(point):\n",
    "        dist += (value - centroid[index])**2\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "0adabafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "5722918d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'summary' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HARSHG~1\\AppData\\Local\\Temp/ipykernel_16544/2676500095.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'summary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    393\u001b[0m         \"\"\"\n\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \"\"\"\n\u001b[1;32m--> 438\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Key '{key}' not present\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'summary' not present\""
     ]
    }
   ],
   "source": [
    "model.wv['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "c33d72eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess_and_preds(pred_model):\n",
    "    \n",
    "    #Import data\n",
    "    emails = pd.read_excel(r\"C:\\Users\\Harsh Garg\\Desktop\\intract\\Email Subject Line Scrapper.xlsx\",'Saved Data')\n",
    "\n",
    "    #Delete irrelevant columns and add relevant columns\n",
    "    emails = emails[['Subject Line']]\n",
    "    \n",
    "    emails['Vector'] = ''\n",
    "\n",
    "    emails['fear'] = ''\n",
    "\n",
    "    emails['anticipation'] = ''\n",
    "\n",
    "    emails['joy'] = ''\n",
    "\n",
    "    emails['trust'] = ''\n",
    "\n",
    "    emails['pride'] = ''\n",
    "\n",
    "    emails['prediction'] = ''\n",
    "\n",
    "    #Will be required for using a 'Switch' function later on\n",
    "    dictionary = {0:'fear',\n",
    "                 1:'anticipation',\n",
    "                 2:'joy',\n",
    "                 3:'trust',\n",
    "                 4:'pride'}\n",
    "    \n",
    "    #to store vectors of the words of emails for k-means later\n",
    "    vectors = pd.DataFrame()\n",
    "    \n",
    "    #Predictions\n",
    "    for index,line in enumerate(emails['Subject Line']):\n",
    "        words = line.split()\n",
    "        vector_word = [0]*100\n",
    "        num_words = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                vector_word += pred_model[word]\n",
    "                num_words+=1\n",
    "            except:\n",
    "                print(word + \" not in my limited vocabulary\")\n",
    "        if num_words==0:\n",
    "            pass\n",
    "        else:\n",
    "            vector_word /= num_words\n",
    "        emails['Vector'].loc[index] = vector_word\n",
    "        vectors = pd.concat([vectors, pd.DataFrame(vector_word).T])\n",
    "        probs = []\n",
    "        \n",
    "        probs.append(dot(vector_word, model.wv['fear'])/(norm(vector_word)*norm(model.wv['fear'])))\n",
    "#         probs.append(pred_model.similarity(words,'fear'))\n",
    "        probs.append(dot(vector_word, model.wv['anticipation'])/(norm(vector_word)*norm(model.wv['anticipation'])))\n",
    "#         probs.append(pred_model.similarity(words,'anticipation'))\n",
    "        probs.append(dot(vector_word, model.wv['joy'])/(norm(vector_word)*norm(model.wv['joy'])))\n",
    "#         probs.append(pred_model.similarity(words,'joy'))\n",
    "        probs.append(dot(vector_word, model.wv['trust'])/(norm(vector_word)*norm(model.wv['trust'])))\n",
    "#         probs.append(pred_model.similarity(words,'trust'))\n",
    "        probs.append(dot(vector_word, model.wv['pride'])/(norm(vector_word)*norm(model.wv['pride'])))\n",
    "#         probs.append(pred_model.similarity(words,'pride'))\n",
    "\n",
    "        probs = softmax(probs)\n",
    "        emails['fear'].loc[index] = probs[0]\n",
    "        emails['anticipation'].loc[index] = probs[1]\n",
    "        emails['joy'].loc[index] = probs[2]\n",
    "        emails['trust'].loc[index] = probs[3]\n",
    "        emails['pride'].loc[index] = probs[4]\n",
    "\n",
    "        emails['prediction'].loc[index] = np.where(probs == max(probs))[0][0]\n",
    "    emails['prediction'] = emails['prediction'].apply(lambda x: dictionary.get(x))\n",
    "\n",
    "    vectors = vectors.reset_index(drop = True)\n",
    "\n",
    "    emails['prediction'].value_counts()\n",
    "\n",
    "    from sklearn.cluster import KMeans\n",
    "    n_clusters = 15\n",
    "    clf = KMeans(n_clusters=n_clusters, max_iter=100, init='k-means++', n_init=1)\n",
    "    labels = clf.fit_predict(vectors)\n",
    "    centroids = clf.cluster_centers_\n",
    "\n",
    "    emails['Cluster'] = labels\n",
    "    emails['abs_dist'] = ''\n",
    "    for index, vect in enumerate(emails['Vector']):\n",
    "        cluster = emails['Cluster'].loc[index]\n",
    "        centroid = centroids[cluster]\n",
    "        emails['abs_dist'].loc[index] = abs_distance(vect, centroid)\n",
    "\n",
    "    min_indices = []\n",
    "    for x in range(0,15):\n",
    "        min_indices.append(emails[emails['abs_dist']==min(emails[emails['Cluster']==x]['abs_dist'])].index)\n",
    "    \n",
    "    return emails, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "5aca3b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aey not in my limited vocabulary\n",
      "Raju, not in my limited vocabulary\n",
      "Salary not in my limited vocabulary\n",
      "Aa not in my limited vocabulary\n",
      "Gayi not in my limited vocabulary\n",
      "Rey not in my limited vocabulary\n",
      "Baba not in my limited vocabulary\n",
      "ðŸ¤“ not in my limited vocabulary\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Word2Vec' object has no attribute 'n_similarity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HARSHG~1\\AppData\\Local\\Temp/ipykernel_16544/3285574478.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmails\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_preprocess_and_preds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\HARSHG~1\\AppData\\Local\\Temp/ipykernel_16544/888864287.py\u001b[0m in \u001b[0;36mdata_preprocess_and_preds\u001b[1;34m(pred_model)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mvectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mprobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fear'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mprobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'anticipation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mprobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'joy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Word2Vec' object has no attribute 'n_similarity'"
     ]
    }
   ],
   "source": [
    "mails, vecs = data_preprocess_and_preds(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a898b",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55545b66",
   "metadata": {},
   "source": [
    "#### Pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "7cdf9a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "# Set file names for train and test data\n",
    "corpus_file = datapath('lee_background.cor')\n",
    "\n",
    "model = FastText(vector_size=100)\n",
    "\n",
    "# build the vocabulary\n",
    "model.build_vocab(corpus_file=corpus_file)\n",
    "\n",
    "# train the model\n",
    "model.train(\n",
    "    corpus_file=corpus_file, epochs=model.epochs,\n",
    "    total_examples=model.corpus_count, total_words=model.corpus_total_words,\n",
    ")\n",
    "\n",
    "wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "90b2eecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0,\n",
       " 'to': 1,\n",
       " 'of': 2,\n",
       " 'in': 3,\n",
       " 'and': 4,\n",
       " 'a': 5,\n",
       " 'is': 6,\n",
       " 'for': 7,\n",
       " 'The': 8,\n",
       " 'on': 9,\n",
       " 'he': 10,\n",
       " 'has': 11,\n",
       " 'says': 12,\n",
       " 'was': 13,\n",
       " 'have': 14,\n",
       " 'that': 15,\n",
       " 'be': 16,\n",
       " 'are': 17,\n",
       " 'will': 18,\n",
       " 'with': 19,\n",
       " 'Mr': 20,\n",
       " 'said.': 21,\n",
       " 'at': 22,\n",
       " 'from': 23,\n",
       " 'by': 24,\n",
       " 'been': 25,\n",
       " 'not': 26,\n",
       " 'as': 27,\n",
       " 'his': 28,\n",
       " 'an': 29,\n",
       " 'it': 30,\n",
       " 'were': 31,\n",
       " 'had': 32,\n",
       " 'after': 33,\n",
       " 'but': 34,\n",
       " 'they': 35,\n",
       " 'said': 36,\n",
       " 'who': 37,\n",
       " 'this': 38,\n",
       " 'Australian': 39,\n",
       " 'we': 40,\n",
       " 'Palestinian': 41,\n",
       " 'their': 42,\n",
       " 'which': 43,\n",
       " 'people': 44,\n",
       " 'two': 45,\n",
       " 'there': 46,\n",
       " 'up': 47,\n",
       " 'about': 48,\n",
       " 'also': 49,\n",
       " 'its': 50,\n",
       " 'out': 51,\n",
       " 'South': 52,\n",
       " 'into': 53,\n",
       " 'would': 54,\n",
       " 'US': 55,\n",
       " 'when': 56,\n",
       " 'against': 57,\n",
       " 'first': 58,\n",
       " 'New': 59,\n",
       " 'more': 60,\n",
       " 'last': 61,\n",
       " 'I': 62,\n",
       " 'He': 63,\n",
       " 'A': 64,\n",
       " 'Israeli': 65,\n",
       " 'Australia': 66,\n",
       " 'if': 67,\n",
       " 'one': 68,\n",
       " 'over': 69,\n",
       " 'United': 70,\n",
       " 'Government': 71,\n",
       " 'or': 72,\n",
       " 'than': 73,\n",
       " 'no': 74,\n",
       " 'all': 75,\n",
       " 'could': 76,\n",
       " 'three': 77,\n",
       " 'before': 78,\n",
       " 'told': 79,\n",
       " 'say': 80,\n",
       " 'new': 81,\n",
       " 'some': 82,\n",
       " 'any': 83,\n",
       " '\"We': 84,\n",
       " 'bin': 85,\n",
       " 'attacks': 86,\n",
       " 'very': 87,\n",
       " 'still': 88,\n",
       " 'just': 89,\n",
       " 'now': 90,\n",
       " 'security': 91,\n",
       " 'police': 92,\n",
       " '\"I': 93,\n",
       " 'Arafat': 94,\n",
       " 'killed': 95,\n",
       " 'our': 96,\n",
       " 'them': 97,\n",
       " 'being': 98,\n",
       " 'forces': 99,\n",
       " 'Minister': 100,\n",
       " 'States': 101,\n",
       " 'But': 102,\n",
       " 'fire': 103,\n",
       " 'what': 104,\n",
       " 'around': 105,\n",
       " 'man': 106,\n",
       " 'other': 107,\n",
       " 'where': 108,\n",
       " 'can': 109,\n",
       " 'next': 110,\n",
       " 'think': 111,\n",
       " 'per': 112,\n",
       " 'day': 113,\n",
       " 'company': 114,\n",
       " 'four': 115,\n",
       " 'Al': 116,\n",
       " 'It': 117,\n",
       " '\"The': 118,\n",
       " 'Qaeda': 119,\n",
       " 'you': 120,\n",
       " 'take': 121,\n",
       " 'officials': 122,\n",
       " 'suicide': 123,\n",
       " 'so': 124,\n",
       " 'President': 125,\n",
       " 'Afghan': 126,\n",
       " 'under': 127,\n",
       " 'Federal': 128,\n",
       " 'In': 129,\n",
       " 'Laden': 130,\n",
       " 'time': 131,\n",
       " 'number': 132,\n",
       " 'made': 133,\n",
       " 'days': 134,\n",
       " 'Taliban': 135,\n",
       " 'through': 136,\n",
       " 'down': 137,\n",
       " 'those': 138,\n",
       " 'meeting': 139,\n",
       " 'Hamas': 140,\n",
       " 'including': 141,\n",
       " 'workers': 142,\n",
       " 'Sydney': 143,\n",
       " 'she': 144,\n",
       " 'Gaza': 145,\n",
       " 'called': 146,\n",
       " 'should': 147,\n",
       " 'military': 148,\n",
       " 'Test': 149,\n",
       " 'second': 150,\n",
       " 'cent': 151,\n",
       " 'since': 152,\n",
       " 'today': 153,\n",
       " 'Islamic': 154,\n",
       " 'back': 155,\n",
       " 'World': 156,\n",
       " 'between': 157,\n",
       " 'September': 158,\n",
       " 'get': 159,\n",
       " 'Wales': 160,\n",
       " 'because': 161,\n",
       " 'members': 162,\n",
       " 'while': 163,\n",
       " '-': 164,\n",
       " 'further': 165,\n",
       " 'going': 166,\n",
       " 'near': 167,\n",
       " 'world': 168,\n",
       " 'Bank': 169,\n",
       " 'report': 170,\n",
       " 'staff': 171,\n",
       " \"Australia's\": 172,\n",
       " 'local': 173,\n",
       " 'former': 174,\n",
       " 'end': 175,\n",
       " 'hours': 176,\n",
       " 'him': 177,\n",
       " 'government': 178,\n",
       " 'attack': 179,\n",
       " 'Israel': 180,\n",
       " 'West': 181,\n",
       " 'only': 182,\n",
       " 'make': 183,\n",
       " 'off': 184,\n",
       " 'do': 185,\n",
       " 'Afghanistan': 186,\n",
       " 'claims': 187,\n",
       " 'international': 188,\n",
       " 'another': 189,\n",
       " 'like': 190,\n",
       " 'leader': 191,\n",
       " 'go': 192,\n",
       " \"it's\": 193,\n",
       " 'many': 194,\n",
       " 'spokesman': 195,\n",
       " 'given': 196,\n",
       " 'expected': 197,\n",
       " 'five': 198,\n",
       " 'left': 199,\n",
       " 'group': 200,\n",
       " 'good': 201,\n",
       " 'Osama': 202,\n",
       " 'looking': 203,\n",
       " 'Qantas': 204,\n",
       " 'saying': 205,\n",
       " 'Tora': 206,\n",
       " 'Prime': 207,\n",
       " 'during': 208,\n",
       " 'put': 209,\n",
       " 'work': 210,\n",
       " 'know': 211,\n",
       " 'air': 212,\n",
       " 'way': 213,\n",
       " 'these': 214,\n",
       " 'action': 215,\n",
       " 'Indian': 216,\n",
       " 'most': 217,\n",
       " 'whether': 218,\n",
       " 'support': 219,\n",
       " 'set': 220,\n",
       " 'found': 221,\n",
       " 'national': 222,\n",
       " 'Afghanistan.': 223,\n",
       " 'died': 224,\n",
       " 'years': 225,\n",
       " 'come': 226,\n",
       " 'metres': 227,\n",
       " 'Yasser': 228,\n",
       " 'year.': 229,\n",
       " 'Foreign': 230,\n",
       " 'how': 231,\n",
       " 'interim': 232,\n",
       " 'six': 233,\n",
       " 'power': 234,\n",
       " '11': 235,\n",
       " 'terrorist': 236,\n",
       " 'team': 237,\n",
       " 'arrested': 238,\n",
       " 'force': 239,\n",
       " 'John': 240,\n",
       " \"don't\": 241,\n",
       " 'trying': 242,\n",
       " 'start': 243,\n",
       " 'part': 244,\n",
       " 'official': 245,\n",
       " 'groups': 246,\n",
       " 'early': 247,\n",
       " 'Bora': 248,\n",
       " 'us': 249,\n",
       " 'Africa': 250,\n",
       " 'several': 251,\n",
       " 'week': 252,\n",
       " 'authorities': 253,\n",
       " 'area': 254,\n",
       " 'war': 255,\n",
       " '100': 256,\n",
       " '50': 257,\n",
       " 'believe': 258,\n",
       " 'third': 259,\n",
       " 'troops': 260,\n",
       " 'Meanwhile,': 261,\n",
       " 'yesterday': 262,\n",
       " 'best': 263,\n",
       " 'Defence': 264,\n",
       " 'want': 265,\n",
       " 'areas': 266,\n",
       " 'militants': 267,\n",
       " 'peace': 268,\n",
       " 'eight': 269,\n",
       " 'need': 270,\n",
       " 'Minister,': 271,\n",
       " 'leaders': 272,\n",
       " 'does': 273,\n",
       " \"Arafat's\": 274,\n",
       " 'following': 275,\n",
       " 'match': 276,\n",
       " 'weather': 277,\n",
       " 'Dr': 278,\n",
       " 'few': 279,\n",
       " 'state': 280,\n",
       " 'confirmed': 281,\n",
       " '12': 282,\n",
       " 'came': 283,\n",
       " 'Sharon': 284,\n",
       " 'close': 285,\n",
       " 'reports': 286,\n",
       " 'Christmas': 287,\n",
       " 'agreement': 288,\n",
       " 'must': 289,\n",
       " 'help': 290,\n",
       " 'Pakistan': 291,\n",
       " 'fighters': 292,\n",
       " 'months': 293,\n",
       " 'brought': 294,\n",
       " 'did': 295,\n",
       " 'then': 296,\n",
       " 'They': 297,\n",
       " 'better': 298,\n",
       " 'took': 299,\n",
       " 'hit': 300,\n",
       " 'believed': 301,\n",
       " 'Peter': 302,\n",
       " 'pay': 303,\n",
       " 'pressure': 304,\n",
       " 'city': 305,\n",
       " 'East': 306,\n",
       " 'taken': 307,\n",
       " '10': 308,\n",
       " 'south': 309,\n",
       " 'maintenance': 310,\n",
       " 'asylum': 311,\n",
       " 'earlier': 312,\n",
       " 'Northern': 313,\n",
       " 'lot': 314,\n",
       " 'held': 315,\n",
       " 'got': 316,\n",
       " 'British': 317,\n",
       " 'accused': 318,\n",
       " 'cut': 319,\n",
       " 'much': 320,\n",
       " 'senior': 321,\n",
       " 'without': 322,\n",
       " 'Melbourne': 323,\n",
       " 'talks': 324,\n",
       " 'injured': 325,\n",
       " 'her': 326,\n",
       " 'well': 327,\n",
       " 'both': 328,\n",
       " 'children': 329,\n",
       " 'too': 330,\n",
       " 'won': 331,\n",
       " 'family': 332,\n",
       " 'Labor': 333,\n",
       " 'Royal': 334,\n",
       " \"that's\": 335,\n",
       " 'shot': 336,\n",
       " 'such': 337,\n",
       " 'see': 338,\n",
       " 'armed': 339,\n",
       " 'court': 340,\n",
       " 'across': 341,\n",
       " 'working': 342,\n",
       " 'economy': 343,\n",
       " 'lead': 344,\n",
       " 'There': 345,\n",
       " 'David': 346,\n",
       " 'asked': 347,\n",
       " 'year': 348,\n",
       " 'key': 349,\n",
       " 'call': 350,\n",
       " 'north': 351,\n",
       " 'Union': 352,\n",
       " 'change': 353,\n",
       " 'statement': 354,\n",
       " 'Commission': 355,\n",
       " 'arrest': 356,\n",
       " 'past': 357,\n",
       " 'even': 358,\n",
       " 'place': 359,\n",
       " 'night': 360,\n",
       " 'information': 361,\n",
       " 'continuing': 362,\n",
       " 'commission': 363,\n",
       " 'play': 364,\n",
       " 'public': 365,\n",
       " 'return': 366,\n",
       " 'despite': 367,\n",
       " 'Authority': 368,\n",
       " 'fighting': 369,\n",
       " 'released': 370,\n",
       " 'morning': 371,\n",
       " 'At': 372,\n",
       " 'December': 373,\n",
       " 'used': 374,\n",
       " 'Waugh': 375,\n",
       " 'economic': 376,\n",
       " 'captured': 377,\n",
       " 'possible': 378,\n",
       " 'Police': 379,\n",
       " 'leading': 380,\n",
       " 'crew': 381,\n",
       " 'George': 382,\n",
       " 'An': 383,\n",
       " 'southern': 384,\n",
       " 'major': 385,\n",
       " 'least': 386,\n",
       " 'Bush': 387,\n",
       " 'Pentagon': 388,\n",
       " 'Afghanistan,': 389,\n",
       " 'unions': 390,\n",
       " 'damage': 391,\n",
       " 'your': 392,\n",
       " 'detainees': 393,\n",
       " 'large': 394,\n",
       " 'use': 395,\n",
       " 'within': 396,\n",
       " 'head': 397,\n",
       " 'winds': 398,\n",
       " 'Hill': 399,\n",
       " 'win': 400,\n",
       " 'stop': 401,\n",
       " 'fires': 402,\n",
       " 'give': 403,\n",
       " 'final': 404,\n",
       " 'million': 405,\n",
       " 'eastern': 406,\n",
       " 'received': 407,\n",
       " 'legal': 408,\n",
       " 'far': 409,\n",
       " 'Two': 410,\n",
       " 'India': 411,\n",
       " 'Queensland': 412,\n",
       " 'charged': 413,\n",
       " 'child': 414,\n",
       " 'high': 415,\n",
       " 'able': 416,\n",
       " '\"If': 417,\n",
       " 'American': 418,\n",
       " 'Williams': 419,\n",
       " 'known': 420,\n",
       " 'director': 421,\n",
       " 'Australians': 422,\n",
       " 'behind': 423,\n",
       " 'may': 424,\n",
       " 'dead': 425,\n",
       " 'services': 426,\n",
       " 'already': 427,\n",
       " 'Lee': 428,\n",
       " 'soldiers': 429,\n",
       " 'heard': 430,\n",
       " 'might': 431,\n",
       " 'process': 432,\n",
       " 'remain': 433,\n",
       " 'board': 434,\n",
       " 'seen': 435,\n",
       " 'radio': 436,\n",
       " 'taking': 437,\n",
       " 'Cup': 438,\n",
       " 'forced': 439,\n",
       " 'training': 440,\n",
       " '15': 441,\n",
       " 'same': 442,\n",
       " 'towards': 443,\n",
       " 'centre': 444,\n",
       " 'water': 445,\n",
       " 'latest': 446,\n",
       " 'morning.': 447,\n",
       " 'Centre': 448,\n",
       " 'cricket': 449,\n",
       " 'conditions': 450,\n",
       " \"there's\": 451,\n",
       " 'interest': 452,\n",
       " 'role': 453,\n",
       " '\"It': 454,\n",
       " 'long': 455,\n",
       " 'failed': 456,\n",
       " 'Palestinians': 457,\n",
       " 'canyoning': 458,\n",
       " 'ago': 459,\n",
       " 'storm': 460,\n",
       " 'thought': 461,\n",
       " 'rates': 462,\n",
       " 'York': 463,\n",
       " 'news': 464,\n",
       " 'strong': 465,\n",
       " 'However,': 466,\n",
       " 'Australia,': 467,\n",
       " 'half': 468,\n",
       " 'position': 469,\n",
       " 'bowler': 470,\n",
       " 'later': 471,\n",
       " 'army': 472,\n",
       " 'due': 473,\n",
       " 'aircraft': 474,\n",
       " 'today.': 475,\n",
       " 'administration': 476,\n",
       " \"I'm\": 477,\n",
       " 'violence': 478,\n",
       " 'Alliance': 479,\n",
       " 'control': 480,\n",
       " 'strikes': 481,\n",
       " 'series': 482,\n",
       " 'After': 483,\n",
       " 'great': 484,\n",
       " 'likely': 485,\n",
       " 'offer': 486,\n",
       " 'Shane': 487,\n",
       " 'Adelaide': 488,\n",
       " 'continue': 489,\n",
       " 'Ms': 490,\n",
       " 'hospital': 491,\n",
       " 'concerned': 492,\n",
       " 'Kandahar': 493,\n",
       " 'Trade': 494,\n",
       " 'claimed': 495,\n",
       " 'right': 496,\n",
       " 'matter': 497,\n",
       " 'Downer': 498,\n",
       " 'special': 499,\n",
       " 'along': 500,\n",
       " 'Nations': 501,\n",
       " 'African': 502,\n",
       " 'month': 503,\n",
       " 'campaign': 504,\n",
       " 'decision': 505,\n",
       " 'buildings': 506,\n",
       " 'envoy': 507,\n",
       " 'own': 508,\n",
       " 'chief': 509,\n",
       " 'death': 510,\n",
       " 'Blue': 511,\n",
       " 'Adventure': 512,\n",
       " 'men': 513,\n",
       " 'launched': 514,\n",
       " 'move': 515,\n",
       " 'officers': 516,\n",
       " 'guilty': 517,\n",
       " 'flight': 518,\n",
       " 'firefighters': 519,\n",
       " 'line': 520,\n",
       " 'rate': 521,\n",
       " 'boat': 522,\n",
       " 'industrial': 523,\n",
       " 'homes': 524,\n",
       " 'west': 525,\n",
       " 'Swiss': 526,\n",
       " 'risk': 527,\n",
       " 'show': 528,\n",
       " 'plans': 529,\n",
       " 'town': 530,\n",
       " 'me': 531,\n",
       " 'Australia.': 532,\n",
       " 'National': 533,\n",
       " 'Middle': 534,\n",
       " 'using': 535,\n",
       " 'weapons': 536,\n",
       " 'helicopters': 537,\n",
       " 'station': 538,\n",
       " 'today,': 539,\n",
       " 'northern': 540,\n",
       " 'Service': 541,\n",
       " 'bus': 542,\n",
       " 'operations': 543,\n",
       " 'probably': 544,\n",
       " 'Mark': 545,\n",
       " 'find': 546,\n",
       " 'carrying': 547,\n",
       " 'Zealand': 548,\n",
       " '14': 549,\n",
       " 'really': 550,\n",
       " 'others': 551,\n",
       " 'life': 552,\n",
       " 'important': 553,\n",
       " 'captain': 554,\n",
       " 'network': 555,\n",
       " 'defence': 556,\n",
       " 'wants': 557,\n",
       " '\"He': 558,\n",
       " 'sure': 559,\n",
       " 'event': 560,\n",
       " \"Laden's\": 561,\n",
       " 'carried': 562,\n",
       " 'Hollingworth': 563,\n",
       " 'Industrial': 564,\n",
       " 'union': 565,\n",
       " 'my': 566,\n",
       " 'jobs': 567,\n",
       " 'Sydney,': 568,\n",
       " '1999': 569,\n",
       " 'health': 570,\n",
       " 'General': 571,\n",
       " 'International': 572,\n",
       " 'UN': 573,\n",
       " 'planning': 574,\n",
       " 'Zinni': 575,\n",
       " 'enough': 576,\n",
       " 'jail': 577,\n",
       " 'Bichel': 578,\n",
       " 'prepared': 579,\n",
       " 'home': 580,\n",
       " 'late': 581,\n",
       " 'side': 582,\n",
       " 'political': 583,\n",
       " 'person': 584,\n",
       " 'hundreds': 585,\n",
       " 'community': 586,\n",
       " 'immediately': 587,\n",
       " 'every': 588,\n",
       " 'tried': 589,\n",
       " 'said,': 590,\n",
       " 'sent': 591,\n",
       " 'McGrath': 592,\n",
       " 'allow': 593,\n",
       " '\"There': 594,\n",
       " 'result': 595,\n",
       " 'fight': 596,\n",
       " 'hard': 597,\n",
       " 'years.': 598,\n",
       " 'comes': 599,\n",
       " 'Council': 600,\n",
       " 'job': 601,\n",
       " 'am': 602,\n",
       " 'beat': 603,\n",
       " 'Secretary': 604,\n",
       " 'went': 605,\n",
       " 'opening': 606,\n",
       " 'caught': 607,\n",
       " 'although': 608,\n",
       " 'race': 609,\n",
       " 'Department': 610,\n",
       " 'emergency': 611,\n",
       " 'kilometres': 612,\n",
       " 'getting': 613,\n",
       " 'become': 614,\n",
       " 'One': 615,\n",
       " 'always': 616,\n",
       " 'reported': 617,\n",
       " 'drop': 618,\n",
       " 'radical': 619,\n",
       " '2': 620,\n",
       " 'opened': 621,\n",
       " 'plane': 622,\n",
       " 'calls': 623,\n",
       " 'Jihad': 624,\n",
       " 'raids': 625,\n",
       " 'HIH': 626,\n",
       " 'seekers': 627,\n",
       " 'issue': 628,\n",
       " 'policy': 629,\n",
       " 'Relations': 630,\n",
       " 'deal': 631,\n",
       " 'Israelis': 632,\n",
       " 'deaths': 633,\n",
       " 'allegations': 634,\n",
       " 'each': 635,\n",
       " 'evidence': 636,\n",
       " 'different': 637,\n",
       " 'Security': 638,\n",
       " 'building': 639,\n",
       " 'growth': 640,\n",
       " 'suspected': 641,\n",
       " 'Unions': 642,\n",
       " 'Woomera': 643,\n",
       " '\"It\\'s': 644,\n",
       " 'laws': 645,\n",
       " 'bombing': 646,\n",
       " 'alleged': 647,\n",
       " 'abuse': 648,\n",
       " 'bombings': 649,\n",
       " 'financial': 650,\n",
       " 'Fire': 651,\n",
       " 'Ariel': 652,\n",
       " 'proposed': 653,\n",
       " 'rejected': 654,\n",
       " 'making': 655,\n",
       " 'opposition': 656,\n",
       " 'full': 657,\n",
       " 'Senator': 658,\n",
       " 'warplanes': 659,\n",
       " 'until': 660,\n",
       " 'details': 661,\n",
       " 'militant': 662,\n",
       " 'Strip': 663,\n",
       " 'days.': 664,\n",
       " 'Immigration': 665,\n",
       " 'airline': 666,\n",
       " 'try': 667,\n",
       " 'running': 668,\n",
       " 'clear': 669,\n",
       " '20': 670,\n",
       " 'Commonwealth': 671,\n",
       " 'river': 672,\n",
       " 'flights': 673,\n",
       " 'Alexander': 674,\n",
       " 'Parliament': 675,\n",
       " \"we're\": 676,\n",
       " 'young': 677,\n",
       " 'currently': 678,\n",
       " 'declared': 679,\n",
       " 'weekend': 680,\n",
       " 'based': 681,\n",
       " 'Howard': 682,\n",
       " 'human': 683,\n",
       " 'executive': 684,\n",
       " 'understand': 685,\n",
       " 'source': 686,\n",
       " 'here': 687,\n",
       " 'bid': 688,\n",
       " 'caves': 689,\n",
       " 'reached': 690,\n",
       " 'believes': 691,\n",
       " 'State': 692,\n",
       " 'yet': 693,\n",
       " 'ago.': 694,\n",
       " 'innings': 695,\n",
       " '18': 696,\n",
       " 'year,': 697,\n",
       " 'look': 698,\n",
       " 'killing': 699,\n",
       " '\"We\\'re': 700,\n",
       " 'surrender': 701,\n",
       " 'time.': 702,\n",
       " 'quite': 703,\n",
       " 'Britain': 704,\n",
       " 'travel': 705,\n",
       " 'Jewish': 706,\n",
       " 'targets': 707,\n",
       " 'Bureau': 708,\n",
       " 'access': 709,\n",
       " 'meet': 710,\n",
       " 'On': 711,\n",
       " 'among': 712,\n",
       " 'flying': 713,\n",
       " 'himself': 714,\n",
       " 'annual': 715,\n",
       " 'July': 716,\n",
       " 'announced': 717,\n",
       " 'actually': 718,\n",
       " \"year's\": 719,\n",
       " 'safety': 720,\n",
       " 'leader,': 721,\n",
       " 'point': 722,\n",
       " 'something': 723,\n",
       " 'Opposition': 724,\n",
       " 'dispute': 725,\n",
       " 'Chief': 726,\n",
       " 'house': 727,\n",
       " 'ended': 728,\n",
       " 'weeks': 729,\n",
       " 'appeared': 730,\n",
       " 'gave': 731,\n",
       " 'responsibility': 732,\n",
       " 'soon': 733,\n",
       " 'step': 734,\n",
       " 'More': 735,\n",
       " 'Warne': 736,\n",
       " 'Mountains': 737,\n",
       " 'huge': 738,\n",
       " 'night.': 739,\n",
       " 'Reserve': 740,\n",
       " \"Afghanistan's\": 741,\n",
       " 'Musharraf': 742,\n",
       " 'guides': 743,\n",
       " 'face': 744,\n",
       " 'overnight': 745,\n",
       " 'certainly': 746,\n",
       " 'thousands': 747,\n",
       " 'means': 748,\n",
       " 'caused': 749,\n",
       " 'Energy': 750,\n",
       " 'gives': 751,\n",
       " 'parts': 752,\n",
       " '\"What': 753,\n",
       " 'figures': 754,\n",
       " 'order': 755,\n",
       " \"can't\": 756,\n",
       " 'biggest': 757,\n",
       " 'Western': 758,\n",
       " 'Test.': 759,\n",
       " 'region': 760,\n",
       " 'changes': 761,\n",
       " 'again': 762,\n",
       " '21': 763,\n",
       " 'issues': 764,\n",
       " 'seven': 765,\n",
       " 'tourists': 766,\n",
       " 'times': 767,\n",
       " 'ground': 768,\n",
       " 'rather': 769,\n",
       " 'top': 770,\n",
       " 'outside': 771,\n",
       " '13': 772,\n",
       " 'people,': 773,\n",
       " 'parties': 774,\n",
       " 'worst': 775,\n",
       " 'wage': 776,\n",
       " 'sources': 777,\n",
       " 'sex': 778,\n",
       " 'decided': 779,\n",
       " '1,000': 780,\n",
       " 'whose': 781,\n",
       " 'Robert': 782,\n",
       " 'Hicks': 783,\n",
       " 'bombers': 784,\n",
       " 'less': 785,\n",
       " 'November': 786,\n",
       " 'away': 787,\n",
       " '200': 788,\n",
       " 'having': 789,\n",
       " \"we've\": 790,\n",
       " 'cost': 791,\n",
       " 'expect': 792,\n",
       " 'Kallis': 793,\n",
       " 'returned': 794,\n",
       " 'investigation': 795,\n",
       " 'them.': 796,\n",
       " 'victory': 797,\n",
       " 'future': 798,\n",
       " 'beyond': 799,\n",
       " 'Sir': 800,\n",
       " 'countries': 801,\n",
       " 'ensure': 802,\n",
       " 'attempt': 803,\n",
       " 'expressed': 804,\n",
       " 'terms': 805,\n",
       " 'needs': 806,\n",
       " 'media': 807,\n",
       " 'arrived': 808,\n",
       " 'run': 809,\n",
       " 'shortly': 810,\n",
       " 'Glenn': 811,\n",
       " 'break': 812,\n",
       " 'refused': 813,\n",
       " 'big': 814,\n",
       " 'chance': 815,\n",
       " 'crash': 816,\n",
       " 'calling': 817,\n",
       " 'inside': 818,\n",
       " 'wave': 819,\n",
       " 'beginning': 820,\n",
       " 'strike': 821,\n",
       " 'Muslim': 822,\n",
       " '\"In': 823,\n",
       " 'placed': 824,\n",
       " 'Detention': 825,\n",
       " 'Anthony': 826,\n",
       " 'main': 827,\n",
       " 'gunmen': 828,\n",
       " 'Donald': 829,\n",
       " 'Day': 830,\n",
       " 'bring': 831,\n",
       " 'money': 832,\n",
       " 'though': 833,\n",
       " 'Boxing': 834,\n",
       " \"he's\": 835,\n",
       " 'party': 836,\n",
       " 'massive': 837,\n",
       " 'involved': 838,\n",
       " 'Safety': 839,\n",
       " 'current': 840,\n",
       " 'foreign': 841,\n",
       " 'Geoff': 842,\n",
       " 'Israel,': 843,\n",
       " 'border': 844,\n",
       " 'bill': 845,\n",
       " 'inquiry': 846,\n",
       " 'it,': 847,\n",
       " 'response': 848,\n",
       " 'serious': 849,\n",
       " 'She': 850,\n",
       " 'sort': 851,\n",
       " \"state's\": 852,\n",
       " 'situation': 853,\n",
       " 'Jacques': 854,\n",
       " 'overnight.': 855,\n",
       " 'morning,': 856,\n",
       " 'banks': 857,\n",
       " 'River': 858,\n",
       " 'forward': 859,\n",
       " 'AFP': 860,\n",
       " 'Pakistani': 861,\n",
       " 'never': 862,\n",
       " 'Daryl': 863,\n",
       " 'Powell': 864,\n",
       " 'ASIO': 865,\n",
       " 'witnesses': 866,\n",
       " 'Russian': 867,\n",
       " 'Brett': 868,\n",
       " 'decide': 869,\n",
       " 'general': 870,\n",
       " 'militia': 871,\n",
       " 'protect': 872,\n",
       " '\"This': 873,\n",
       " 'address': 874,\n",
       " 'boy': 875,\n",
       " 'available': 876,\n",
       " 'according': 877,\n",
       " 'attacks.': 878,\n",
       " 'warned': 879,\n",
       " 'collapse': 880,\n",
       " 'cannot': 881,\n",
       " 'Monday': 882,\n",
       " 'president': 883,\n",
       " 'As': 884,\n",
       " 'denied': 885,\n",
       " 'Anglican': 886,\n",
       " 'residents': 887,\n",
       " 'Martin': 888,\n",
       " 'Governor-General': 889,\n",
       " 'struck': 890,\n",
       " 'act': 891,\n",
       " 'short': 892,\n",
       " 'royal': 893,\n",
       " 'movement': 894,\n",
       " 'Local': 895,\n",
       " 'States.': 896,\n",
       " 'entered': 897,\n",
       " 'lives': 898,\n",
       " 'disease': 899,\n",
       " 'trees': 900,\n",
       " 'cancer': 901,\n",
       " 'fact': 902,\n",
       " 'level': 903,\n",
       " 'mountains': 904,\n",
       " 'prevent': 905,\n",
       " 'giving': 906,\n",
       " 'heavy': 907,\n",
       " 'feel': 908,\n",
       " 'Kabul': 909,\n",
       " '48': 910,\n",
       " 'longer': 911,\n",
       " '\"They': 912,\n",
       " 'followed': 913,\n",
       " 'commanders': 914,\n",
       " 'changed': 915,\n",
       " 'bomb': 916,\n",
       " 'trip': 917,\n",
       " 'moved': 918,\n",
       " 'offices': 919,\n",
       " 'country': 920,\n",
       " '2,000': 921,\n",
       " 'well,': 922,\n",
       " 'insurance': 923,\n",
       " 'fired': 924,\n",
       " 'Rural': 925,\n",
       " 'total': 926,\n",
       " 'front': 927,\n",
       " 'coming': 928,\n",
       " 'study': 929,\n",
       " 'time,': 930,\n",
       " 'proposals': 931,\n",
       " 'helicopter': 932,\n",
       " 'him.': 933,\n",
       " 'India.': 934,\n",
       " 'Justice': 935,\n",
       " 'car': 936,\n",
       " 'ever': 937,\n",
       " '5,000': 938,\n",
       " 'areas.': 939,\n",
       " 'post': 940,\n",
       " 'accident': 941,\n",
       " 'management': 942,\n",
       " 'member': 943,\n",
       " 'began': 944,\n",
       " 'industry.': 945,\n",
       " 'stage': 946,\n",
       " 'area.': 947,\n",
       " 'hearings': 948,\n",
       " 'Pacific': 949,\n",
       " 'nearly': 950,\n",
       " 'Suharto': 951,\n",
       " 'confidence': 952,\n",
       " 'share': 953,\n",
       " 'ruled': 954,\n",
       " 'absolutely': 955,\n",
       " 'tour': 956,\n",
       " 'threat': 957,\n",
       " 'fast': 958,\n",
       " '\"These': 959,\n",
       " 'hour': 960,\n",
       " 'significant': 961,\n",
       " 'small': 962,\n",
       " 'yacht': 963,\n",
       " 'terror': 964,\n",
       " 'places': 965,\n",
       " 'tanks': 966,\n",
       " 'overall': 967,\n",
       " 'nine': 968,\n",
       " 'Islands': 969,\n",
       " 'Hobart': 970,\n",
       " 'base': 971,\n",
       " 'secretary': 972,\n",
       " 'control.': 973,\n",
       " 'anything': 974,\n",
       " 'tomorrow.': 975,\n",
       " 'fighter': 976,\n",
       " 'population': 977,\n",
       " 'ministers': 978,\n",
       " 'French': 979,\n",
       " 'Hewitt': 980,\n",
       " 'House': 981,\n",
       " 'list': 982,\n",
       " 'costs': 983,\n",
       " 'burning': 984,\n",
       " 'confident': 985,\n",
       " 'Highway': 986,\n",
       " 'rule': 987,\n",
       " 'If': 988,\n",
       " 'Workers': 989,\n",
       " 'accept': 990,\n",
       " 'tribal': 991,\n",
       " 'White': 992,\n",
       " 'quickly': 993,\n",
       " 'months.': 994,\n",
       " '\"You': 995,\n",
       " 'speaking': 996,\n",
       " 'global': 997,\n",
       " 'survey': 998,\n",
       " 'deadly': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "c568c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fear = wv['fear']\n",
    "anticipation = wv['anticipation']\n",
    "joy = wv['joy']\n",
    "trust = wv['trust']\n",
    "pride = wv['pride']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "96b26fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_excel(r\"C:\\Users\\Harsh Garg\\Desktop\\intract\\Email Subject Line Scrapper.xlsx\",'Saved Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "2df5c2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Message Id</th>\n",
       "      <th>From</th>\n",
       "      <th>Email</th>\n",
       "      <th>Subject Line</th>\n",
       "      <th>Concated Body</th>\n",
       "      <th>Email from</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-01 19:26:52</td>\n",
       "      <td>17c3c24c23506d3c</td>\n",
       "      <td>Paytm Offers</td>\n",
       "      <td>noreply@paytmoffers.in</td>\n",
       "      <td>Aey Raju, Salary Aa Gayi Rey Baba ðŸ¤“</td>\n",
       "      <td>Paytm par deals check kar to</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-01 13:50:21</td>\n",
       "      <td>17c3af0a22235012</td>\n",
       "      <td>Swiggy Instamart</td>\n",
       "      <td>alerts@updates.swiggy.in</td>\n",
       "      <td>October's first grocery bill will be a short o...</td>\n",
       "      <td>Email Template \\n[image: Get 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-01 11:43:23</td>\n",
       "      <td>17c3a816c53f6b1c</td>\n",
       "      <td>Zomato</td>\n",
       "      <td>noreply@mailers.zomato.com</td>\n",
       "      <td>Guess who always makes you smile? ðŸ˜ƒ</td>\n",
       "      <td>Here are your hints - you lov</td>\n",
       "      <td>abhishek12318@gmail.com</td>\n",
       "      <td>Subject: Guess who always makes you smile? ðŸ˜ƒ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date        Message Id              From  \\\n",
       "0 2021-10-01 19:26:52  17c3c24c23506d3c      Paytm Offers   \n",
       "1 2021-10-01 13:50:21  17c3af0a22235012  Swiggy Instamart   \n",
       "2 2021-10-01 11:43:23  17c3a816c53f6b1c            Zomato   \n",
       "\n",
       "                        Email  \\\n",
       "0      noreply@paytmoffers.in   \n",
       "1    alerts@updates.swiggy.in   \n",
       "2  noreply@mailers.zomato.com   \n",
       "\n",
       "                                        Subject Line  \\\n",
       "0                Aey Raju, Salary Aa Gayi Rey Baba ðŸ¤“   \n",
       "1  October's first grocery bill will be a short o...   \n",
       "2                Guess who always makes you smile? ðŸ˜ƒ   \n",
       "\n",
       "                    Concated Body               Email from  \\\n",
       "0    Paytm par deals check kar to                      NaN   \n",
       "1  Email Template \\n[image: Get 3                      NaN   \n",
       "2   Here are your hints - you lov  abhishek12318@gmail.com   \n",
       "\n",
       "                                     Unnamed: 7  \n",
       "0                                           NaN  \n",
       "1                                           NaN  \n",
       "2  Subject: Guess who always makes you smile? ðŸ˜ƒ  "
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "37e0cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "emails = emails[['Subject Line']]\n",
    "\n",
    "emails['Vector'] = ''\n",
    "\n",
    "emails['fear'] = ''\n",
    "\n",
    "emails['anticipation'] = ''\n",
    "\n",
    "emails['joy'] = ''\n",
    "\n",
    "emails['trust'] = ''\n",
    "\n",
    "emails['pride'] = ''\n",
    "\n",
    "emails['prediction'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "c310ea9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Line</th>\n",
       "      <th>Vector</th>\n",
       "      <th>fear</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>joy</th>\n",
       "      <th>trust</th>\n",
       "      <th>pride</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aey Raju, Salary Aa Gayi Rey Baba ðŸ¤“</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Subject Line Vector fear anticipation joy trust  \\\n",
       "0  Aey Raju, Salary Aa Gayi Rey Baba ðŸ¤“                                      \n",
       "\n",
       "  pride prediction  \n",
       "0                   "
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "6fca52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "3c599ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {0:'fear',\n",
    "             1:'anticipation',\n",
    "             2:'joy',\n",
    "             3:'trust',\n",
    "             4:'pride'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "4e3a2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "d936fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,line in enumerate(emails['Subject Line']):\n",
    "    words = line.split()\n",
    "    vector_word = [0]*100\n",
    "    for word in words:\n",
    "        vector_word += wv[word]\n",
    "    vector_word /= len(words)\n",
    "    emails['Vector'].loc[index] = vector_word\n",
    "    vectors = pd.concat([vectors, pd.DataFrame(vector_word).T])\n",
    "    probs = []\n",
    "    probs.append(wv.n_similarity(words,['fear']))\n",
    "    probs.append(wv.n_similarity(words,['anticipation']))\n",
    "    probs.append(wv.n_similarity(words,['joy']))\n",
    "    probs.append(wv.n_similarity(words,['trust']))\n",
    "    probs.append(wv.n_similarity(words,['pride']))\n",
    "    probs = softmax(probs)\n",
    "    emails['fear'].loc[index] = probs[0]\n",
    "    emails['anticipation'].loc[index] = probs[1]\n",
    "    emails['joy'].loc[index] = probs[2]\n",
    "    emails['trust'].loc[index] = probs[3]\n",
    "    emails['pride'].loc[index] = probs[4]\n",
    "    \n",
    "    emails['prediction'].loc[index] = np.where(probs == max(probs))[0][0]\n",
    "\n",
    "emails['prediction'] = emails['prediction'].apply(lambda x: dictionary.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "fb701b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Line</th>\n",
       "      <th>Vector</th>\n",
       "      <th>fear</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>joy</th>\n",
       "      <th>trust</th>\n",
       "      <th>pride</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aey Raju, Salary Aa Gayi Rey Baba ðŸ¤“</td>\n",
       "      <td>[-0.029583398674731143, 0.04560574136849027, -...</td>\n",
       "      <td>0.200064</td>\n",
       "      <td>0.200065</td>\n",
       "      <td>0.199753</td>\n",
       "      <td>0.200059</td>\n",
       "      <td>0.200058</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>October's first grocery bill will be a short o...</td>\n",
       "      <td>[-0.203917137067765, 0.3200864117126912, -0.37...</td>\n",
       "      <td>0.200053</td>\n",
       "      <td>0.200059</td>\n",
       "      <td>0.199777</td>\n",
       "      <td>0.200055</td>\n",
       "      <td>0.200055</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Guess who always makes you smile? ðŸ˜ƒ</td>\n",
       "      <td>[-0.13193609658628702, 0.20359431293659977, -0...</td>\n",
       "      <td>0.200057</td>\n",
       "      <td>0.200061</td>\n",
       "      <td>0.199765</td>\n",
       "      <td>0.200057</td>\n",
       "      <td>0.200059</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INCOMING:Max G.I.Joe Ninja action ft.Henry Gol...</td>\n",
       "      <td>[-0.07782417975977296, 0.12250001124006563, -0...</td>\n",
       "      <td>0.200053</td>\n",
       "      <td>0.200061</td>\n",
       "      <td>0.199772</td>\n",
       "      <td>0.200057</td>\n",
       "      <td>0.200057</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New AC/TV/Laptop on your mind?</td>\n",
       "      <td>[-0.19056224822998047, 0.297525935433805, -0.3...</td>\n",
       "      <td>0.200055</td>\n",
       "      <td>0.200062</td>\n",
       "      <td>0.199765</td>\n",
       "      <td>0.20006</td>\n",
       "      <td>0.200058</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Subject Line  \\\n",
       "0                Aey Raju, Salary Aa Gayi Rey Baba ðŸ¤“   \n",
       "1  October's first grocery bill will be a short o...   \n",
       "2                Guess who always makes you smile? ðŸ˜ƒ   \n",
       "3  INCOMING:Max G.I.Joe Ninja action ft.Henry Gol...   \n",
       "4                     New AC/TV/Laptop on your mind?   \n",
       "\n",
       "                                              Vector      fear anticipation  \\\n",
       "0  [-0.029583398674731143, 0.04560574136849027, -...  0.200064     0.200065   \n",
       "1  [-0.203917137067765, 0.3200864117126912, -0.37...  0.200053     0.200059   \n",
       "2  [-0.13193609658628702, 0.20359431293659977, -0...  0.200057     0.200061   \n",
       "3  [-0.07782417975977296, 0.12250001124006563, -0...  0.200053     0.200061   \n",
       "4  [-0.19056224822998047, 0.297525935433805, -0.3...  0.200055     0.200062   \n",
       "\n",
       "        joy     trust     pride    prediction  \n",
       "0  0.199753  0.200059  0.200058  anticipation  \n",
       "1  0.199777  0.200055  0.200055  anticipation  \n",
       "2  0.199765  0.200057  0.200059  anticipation  \n",
       "3  0.199772  0.200057  0.200057  anticipation  \n",
       "4  0.199765   0.20006  0.200058  anticipation  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "731de180",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectors.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "768f5dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anticipation    1507\n",
       "trust             17\n",
       "pride             15\n",
       "joy                2\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "374382dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "n_clusters = 15\n",
    "clf = KMeans(n_clusters=n_clusters, max_iter=100, init='k-means++', n_init=1)\n",
    "labels = clf.fit_predict(vectors)\n",
    "centroids = clf.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "23b91c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_distance(point, centroid):\n",
    "    dist = 0\n",
    "    for index, value in enumerate(point):\n",
    "        dist += abs(value - centroid[index])\n",
    "    return dist\n",
    "\n",
    "def square_distance(point, centroid):\n",
    "    dist = 0\n",
    "    for index, value in enumerate(point):\n",
    "        dist += (value - centroid[index])**2\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "13263b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harsh Garg\\miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "emails['Cluster'] = labels\n",
    "emails['abs_dist'] = ''\n",
    "for index, vect in enumerate(emails['Vector']):\n",
    "    cluster = emails['Cluster'].loc[index]\n",
    "    centroid = centroids[cluster]\n",
    "    emails['abs_dist'].loc[index] = abs_distance(vect, centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "ad81f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_indices = []\n",
    "for x in range(0,15):\n",
    "    min_indices.append(emails[emails['abs_dist']==min(emails[emails['Cluster']==x]['abs_dist'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "edf8fdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282    Hereâ€™s what your awesome week looks like!\n",
      "Name: Subject Line, dtype: object\n",
      "1299    Lessons From a Body Sculptor on What Really Ch...\n",
      "Name: Subject Line, dtype: object\n",
      "970    IITM: IRIS Webinar Series\n",
      "Name: Subject Line, dtype: object\n",
      "824    Warning! This is not a Price Drop\n",
      "Name: Subject Line, dtype: object\n",
      "1303    MSP of Rabi crops increased; Rs. 10,000 crore ...\n",
      "Name: Subject Line, dtype: object\n",
      "800    Good Health Essential #1: Oximeters\\n\\n\n",
      "Name: Subject Line, dtype: object\n",
      "466    LOVE Surprises?\n",
      "467    LOVE Surprises?\n",
      "776    LOVE Surprises?\n",
      "Name: Subject Line, dtype: object\n",
      "887    Something for the Women in your Life!\n",
      "Name: Subject Line, dtype: object\n",
      "1232    Whatâ€™s going on with our 10-minute delivery?\n",
      "Name: Subject Line, dtype: object\n",
      "284    Schedule your manicure after watching these na...\n",
      "Name: Subject Line, dtype: object\n",
      "238    Crazy' surprises inside!\n",
      "239    Crazy' surprises inside!\n",
      "Name: Subject Line, dtype: object\n",
      "64      Twinkle Twinkle SUPERSTâ­R\n",
      "65      Twinkle Twinkle SUPERSTâ­R\n",
      "1207    Twinkle Twinkle SUPERSTâ­R\n",
      "1208    Twinkle Twinkle SUPERSTâ­R\n",
      "Name: Subject Line, dtype: object\n",
      "1189    now live: big brands fest!\n",
      "Name: Subject Line, dtype: object\n",
      "703    Your Zomato order from Khaas-Parathas\n",
      "883    Your Zomato order from Khaas-Parathas\n",
      "Name: Subject Line, dtype: object\n",
      "59      Your dream job and salary is a click away!\n",
      "1179    Your dream job and salary is a click away!\n",
      "Name: Subject Line, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,15):\n",
    "    print(emails['Subject Line'].loc[min_indices[x][:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "f3c46988",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails.to_excel(r\"C:\\Users\\Harsh Garg\\Desktop\\intract\\FastText_pretrained_lee_corpus.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177621b6",
   "metadata": {},
   "source": [
    "#### Trained on scrapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "d653a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "def create_dataset(keyword):\n",
    "    scrapped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/' + keyword)\n",
    "    article = scrapped_data.read()\n",
    "\n",
    "    parsed_article = bs.BeautifulSoup(article,'html.parser')\n",
    "\n",
    "    paragraphs = parsed_article.find_all('p')\n",
    "\n",
    "    article_text = \"\"\n",
    "\n",
    "    for p in paragraphs:\n",
    "        article_text += p.text\n",
    "\n",
    "    # Cleaing the text\n",
    "    processed_article = article_text.lower()\n",
    "    processed_article = re.sub('[^a-zA-Z]', '', processed_article )\n",
    "    processed_article = re.sub(r'\\s+', ' ', processed_article)\n",
    "    \n",
    "    stopwords = ENGLISH_STOP_WORDS.union(['swiggy','zomato','aggarwal','harsh','garg','abhishek','2021','11','ve','ncr',\n",
    "                                          'delhi','sep','october','india','anita','harshgarg297@gmail.com',\n",
    "                                          'abhishek12318@gmail.com','000','10','100','12','13','14','143','16','19','20','2020',\n",
    "                                          '2022','21','2192573831','24','25','250','2568642602','26th','30','360','3657963965',\n",
    "                                          '420','499','50','500','60','75','80','90','99','999','abhishek12318', 'com', \n",
    "                                          'gmail', 'harshgarg297','ramji','kyc','ft','prathamesh','pathwardhan','singh','flipkart',\n",
    "                                          'amazon','january','jan','feb','february','mar','march','apr','april','may','june','jun',\n",
    "                                          'july','aug','august','sept','september','oct','nov','november','dec','december'])\n",
    "\n",
    "\n",
    "    for i in range(len(all_words)):\n",
    "        all_words[i] = [w for w in all_words[i] if w not in stopwords]\n",
    "        \n",
    "    return all_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "805c441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "dataset += create_dataset('emotions')\n",
    "dataset += create_dataset('fear')\n",
    "dataset += create_dataset('anticipation')\n",
    "dataset += create_dataset('joy')\n",
    "dataset += create_dataset('trust')\n",
    "dataset += create_dataset('pride')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "73eea9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27252"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "c5191a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(341007, 2048580)"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "model = FastText(vector_size=100, window=2, min_count=1)  # instantiate\n",
    "model.build_vocab(dataset)\n",
    "model.train(dataset, total_examples=len(dataset), epochs=10)  # train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "1f586751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_distance(point, centroid):\n",
    "    dist = 0\n",
    "    for index, value in enumerate(point):\n",
    "        dist += abs(value - centroid[index])\n",
    "    return dist\n",
    "\n",
    "def square_distance(point, centroid):\n",
    "    dist = 0\n",
    "    for index, value in enumerate(point):\n",
    "        dist += (value - centroid[index])**2\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "9894ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "282f9462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess_and_preds(pred_model):\n",
    "    \n",
    "    #Import data\n",
    "    emails = pd.read_excel(r\"C:\\Users\\Harsh Garg\\Desktop\\intract\\Email Subject Line Scrapper.xlsx\",'Saved Data')\n",
    "\n",
    "    #Delete irrelevant columns and add relevant columns\n",
    "    emails = emails[['Subject Line']]\n",
    "    \n",
    "    emails['Vector'] = ''\n",
    "\n",
    "    emails['fear'] = ''\n",
    "\n",
    "    emails['anticipation'] = ''\n",
    "\n",
    "    emails['joy'] = ''\n",
    "\n",
    "    emails['trust'] = ''\n",
    "\n",
    "    emails['pride'] = ''\n",
    "\n",
    "    emails['prediction'] = ''\n",
    "\n",
    "    #Will be required for using a 'Switch' function later on\n",
    "    dictionary = {0:'fear',\n",
    "                 1:'anticipation',\n",
    "                 2:'joy',\n",
    "                 3:'trust',\n",
    "                 4:'pride'}\n",
    "    \n",
    "    #to store vectors of the words of emails for k-means later\n",
    "    vectors = pd.DataFrame()\n",
    "    \n",
    "    #Predictions\n",
    "    for index,line in enumerate(emails['Subject Line']):\n",
    "        words = line.split()\n",
    "        vector_word = [0]*100\n",
    "        for word in words:\n",
    "            vector_word += pred_model[word]\n",
    "        vector_word /= len(words)\n",
    "        emails['Vector'].loc[index] = vector_word\n",
    "        vectors = pd.concat([vectors, pd.DataFrame(vector_word).T])\n",
    "        probs = []\n",
    "        probs.append(pred_model.n_similarity(words,['fear']))\n",
    "        probs.append(pred_model.n_similarity(words,['anticipation']))\n",
    "        probs.append(pred_model.n_similarity(words,['joy']))\n",
    "        probs.append(pred_model.n_similarity(words,['trust']))\n",
    "        probs.append(pred_model.n_similarity(words,['pride']))\n",
    "        probs = softmax(probs)\n",
    "        emails['fear'].loc[index] = probs[0]\n",
    "        emails['anticipation'].loc[index] = probs[1]\n",
    "        emails['joy'].loc[index] = probs[2]\n",
    "        emails['trust'].loc[index] = probs[3]\n",
    "        emails['pride'].loc[index] = probs[4]\n",
    "\n",
    "        emails['prediction'].loc[index] = np.where(probs == max(probs))[0][0]\n",
    "    emails['prediction'] = emails['prediction'].apply(lambda x: dictionary.get(x))\n",
    "\n",
    "    vectors = vectors.reset_index(drop = True)\n",
    "\n",
    "    emails['prediction'].value_counts()\n",
    "\n",
    "    from sklearn.cluster import KMeans\n",
    "    n_clusters = 15\n",
    "    clf = KMeans(n_clusters=n_clusters, max_iter=100, init='k-means++', n_init=1)\n",
    "    labels = clf.fit_predict(vectors)\n",
    "    centroids = clf.cluster_centers_\n",
    "\n",
    "    emails['Cluster'] = labels\n",
    "    emails['abs_dist'] = ''\n",
    "    for index, vect in enumerate(emails['Vector']):\n",
    "        cluster = emails['Cluster'].loc[index]\n",
    "        centroid = centroids[cluster]\n",
    "        emails['abs_dist'].loc[index] = abs_distance(vect, centroid)\n",
    "\n",
    "    min_indices = []\n",
    "    for x in range(0,15):\n",
    "        min_indices.append(emails[emails['abs_dist']==min(emails[emails['Cluster']==x]['abs_dist'])].index)\n",
    "    \n",
    "    return emails, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "9b61a54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harsh Garg\\miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "mails, vecs = data_preprocess_and_preds(model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "90fe7cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1541, 10), (1541, 100))"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mails.shape,vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "855faddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282    Hereâ€™s what your awesome week looks like!\n",
      "Name: Subject Line, dtype: object\n",
      "1299    Lessons From a Body Sculptor on What Really Ch...\n",
      "Name: Subject Line, dtype: object\n",
      "970    IITM: IRIS Webinar Series\n",
      "Name: Subject Line, dtype: object\n",
      "824    Warning! This is not a Price Drop\n",
      "Name: Subject Line, dtype: object\n",
      "1303    MSP of Rabi crops increased; Rs. 10,000 crore ...\n",
      "Name: Subject Line, dtype: object\n",
      "800    Good Health Essential #1: Oximeters\\n\\n\n",
      "Name: Subject Line, dtype: object\n",
      "466    LOVE Surprises?\n",
      "467    LOVE Surprises?\n",
      "776    LOVE Surprises?\n",
      "Name: Subject Line, dtype: object\n",
      "887    Something for the Women in your Life!\n",
      "Name: Subject Line, dtype: object\n",
      "1232    Whatâ€™s going on with our 10-minute delivery?\n",
      "Name: Subject Line, dtype: object\n",
      "284    Schedule your manicure after watching these na...\n",
      "Name: Subject Line, dtype: object\n",
      "238    Crazy' surprises inside!\n",
      "239    Crazy' surprises inside!\n",
      "Name: Subject Line, dtype: object\n",
      "64      Twinkle Twinkle SUPERSTâ­R\n",
      "65      Twinkle Twinkle SUPERSTâ­R\n",
      "1207    Twinkle Twinkle SUPERSTâ­R\n",
      "1208    Twinkle Twinkle SUPERSTâ­R\n",
      "Name: Subject Line, dtype: object\n",
      "1189    now live: big brands fest!\n",
      "Name: Subject Line, dtype: object\n",
      "703    Your Zomato order from Khaas-Parathas\n",
      "883    Your Zomato order from Khaas-Parathas\n",
      "Name: Subject Line, dtype: object\n",
      "59      Your dream job and salary is a click away!\n",
      "1179    Your dream job and salary is a click away!\n",
      "Name: Subject Line, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,15):\n",
    "    print(mails['Subject Line'].loc[min_indices[x][:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "eeb4eb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Line</th>\n",
       "      <th>Vector</th>\n",
       "      <th>fear</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>joy</th>\n",
       "      <th>trust</th>\n",
       "      <th>pride</th>\n",
       "      <th>prediction</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>abs_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New AC/TV/Laptop on your mind?</td>\n",
       "      <td>[0.0001063522882759571, 0.0009480616252403706,...</td>\n",
       "      <td>0.195452</td>\n",
       "      <td>0.192447</td>\n",
       "      <td>0.180315</td>\n",
       "      <td>0.225437</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>trust</td>\n",
       "      <td>12</td>\n",
       "      <td>0.065703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New AC/TV/Laptop on your mind?</td>\n",
       "      <td>[0.0001063522882759571, 0.0009480616252403706,...</td>\n",
       "      <td>0.195452</td>\n",
       "      <td>0.192447</td>\n",
       "      <td>0.180315</td>\n",
       "      <td>0.225437</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>trust</td>\n",
       "      <td>12</td>\n",
       "      <td>0.065703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Make sure your meal meets your fitness goals. ðŸ’ªðŸ»</td>\n",
       "      <td>[0.001995351134408136, 0.0006653189710858795, ...</td>\n",
       "      <td>0.180146</td>\n",
       "      <td>0.190449</td>\n",
       "      <td>0.208112</td>\n",
       "      <td>0.227242</td>\n",
       "      <td>0.19405</td>\n",
       "      <td>trust</td>\n",
       "      <td>8</td>\n",
       "      <td>0.049649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Your Swiggy order was delivered superfast!</td>\n",
       "      <td>[0.000664175187315171, 0.0007133712812598484, ...</td>\n",
       "      <td>0.171943</td>\n",
       "      <td>0.194315</td>\n",
       "      <td>0.209483</td>\n",
       "      <td>0.223443</td>\n",
       "      <td>0.200816</td>\n",
       "      <td>trust</td>\n",
       "      <td>8</td>\n",
       "      <td>0.042764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Put month-end blues on snooze â°</td>\n",
       "      <td>[0.0009930937376338989, 0.0016646496551402379,...</td>\n",
       "      <td>0.17102</td>\n",
       "      <td>0.201793</td>\n",
       "      <td>0.203777</td>\n",
       "      <td>0.226361</td>\n",
       "      <td>0.197049</td>\n",
       "      <td>trust</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>The July highlights on Nintendo Switch</td>\n",
       "      <td>[0.0014786439811966072, 0.000670435544331364, ...</td>\n",
       "      <td>0.187761</td>\n",
       "      <td>0.207598</td>\n",
       "      <td>0.177065</td>\n",
       "      <td>0.224682</td>\n",
       "      <td>0.202893</td>\n",
       "      <td>trust</td>\n",
       "      <td>12</td>\n",
       "      <td>0.062502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>\"PSA for DBS Broly players: Medium and EX gra...\"</td>\n",
       "      <td>[0.00021032798556714423, -5.262130111481788e-0...</td>\n",
       "      <td>0.209273</td>\n",
       "      <td>0.209134</td>\n",
       "      <td>0.191791</td>\n",
       "      <td>0.212652</td>\n",
       "      <td>0.177149</td>\n",
       "      <td>trust</td>\n",
       "      <td>8</td>\n",
       "      <td>0.055817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>Party with DJ Tarun and DJ Shreya</td>\n",
       "      <td>[-0.0003432029869665192, -0.000619665162438260...</td>\n",
       "      <td>0.19647</td>\n",
       "      <td>0.164867</td>\n",
       "      <td>0.213016</td>\n",
       "      <td>0.215098</td>\n",
       "      <td>0.210549</td>\n",
       "      <td>trust</td>\n",
       "      <td>8</td>\n",
       "      <td>0.088762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>3 Essential Guitar Scales</td>\n",
       "      <td>[-0.0003252516617067158, -0.002024852299655322...</td>\n",
       "      <td>0.202556</td>\n",
       "      <td>0.203229</td>\n",
       "      <td>0.205574</td>\n",
       "      <td>0.209002</td>\n",
       "      <td>0.179639</td>\n",
       "      <td>trust</td>\n",
       "      <td>8</td>\n",
       "      <td>0.129149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>Trademark Search and Classification in IndiaÂ Â®</td>\n",
       "      <td>[0.00030376134340518286, 0.001929714587926615,...</td>\n",
       "      <td>0.215415</td>\n",
       "      <td>0.193609</td>\n",
       "      <td>0.183701</td>\n",
       "      <td>0.220481</td>\n",
       "      <td>0.186793</td>\n",
       "      <td>trust</td>\n",
       "      <td>12</td>\n",
       "      <td>0.079671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Subject Line  \\\n",
       "4                        New AC/TV/Laptop on your mind?   \n",
       "5                        New AC/TV/Laptop on your mind?   \n",
       "6      Make sure your meal meets your fitness goals. ðŸ’ªðŸ»   \n",
       "10           Your Swiggy order was delivered superfast!   \n",
       "11                      Put month-end blues on snooze â°   \n",
       "...                                                 ...   \n",
       "1516             The July highlights on Nintendo Switch   \n",
       "1518  \"PSA for DBS Broly players: Medium and EX gra...\"   \n",
       "1534                  Party with DJ Tarun and DJ Shreya   \n",
       "1535                          3 Essential Guitar Scales   \n",
       "1538     Trademark Search and Classification in IndiaÂ Â®   \n",
       "\n",
       "                                                 Vector      fear  \\\n",
       "4     [0.0001063522882759571, 0.0009480616252403706,...  0.195452   \n",
       "5     [0.0001063522882759571, 0.0009480616252403706,...  0.195452   \n",
       "6     [0.001995351134408136, 0.0006653189710858795, ...  0.180146   \n",
       "10    [0.000664175187315171, 0.0007133712812598484, ...  0.171943   \n",
       "11    [0.0009930937376338989, 0.0016646496551402379,...   0.17102   \n",
       "...                                                 ...       ...   \n",
       "1516  [0.0014786439811966072, 0.000670435544331364, ...  0.187761   \n",
       "1518  [0.00021032798556714423, -5.262130111481788e-0...  0.209273   \n",
       "1534  [-0.0003432029869665192, -0.000619665162438260...   0.19647   \n",
       "1535  [-0.0003252516617067158, -0.002024852299655322...  0.202556   \n",
       "1538  [0.00030376134340518286, 0.001929714587926615,...  0.215415   \n",
       "\n",
       "     anticipation       joy     trust     pride prediction  Cluster  abs_dist  \n",
       "4        0.192447  0.180315  0.225437  0.206349      trust       12  0.065703  \n",
       "5        0.192447  0.180315  0.225437  0.206349      trust       12  0.065703  \n",
       "6        0.190449  0.208112  0.227242   0.19405      trust        8  0.049649  \n",
       "10       0.194315  0.209483  0.223443  0.200816      trust        8  0.042764  \n",
       "11       0.201793  0.203777  0.226361  0.197049      trust        0   0.10474  \n",
       "...           ...       ...       ...       ...        ...      ...       ...  \n",
       "1516     0.207598  0.177065  0.224682  0.202893      trust       12  0.062502  \n",
       "1518     0.209134  0.191791  0.212652  0.177149      trust        8  0.055817  \n",
       "1534     0.164867  0.213016  0.215098  0.210549      trust        8  0.088762  \n",
       "1535     0.203229  0.205574  0.209002  0.179639      trust        8  0.129149  \n",
       "1538     0.193609  0.183701  0.220481  0.186793      trust       12  0.079671  \n",
       "\n",
       "[261 rows x 10 columns]"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mails[mails['prediction']=='trust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "c3cb6df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fear            401\n",
       "anticipation    394\n",
       "trust           261\n",
       "joy             258\n",
       "pride           227\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mails['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "0a86204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mails.to_excel(r\"C:\\Users\\Harsh Garg\\Desktop\\intract\\FastText_custom_trained_wikipedia_5_emotions_scraped.xlsx\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
